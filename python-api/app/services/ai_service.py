"""
Servicio de IA usando solo LLM (Groq)
Arquitectura simplificada para consistencia entre ambientes
"""

from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from typing import Dict, Any, List, Optional
import logging
import time
import json
import re

from app.config import settings
from app.models import TicketCategory, TicketSentiment

# Configurar logger
logger = logging.getLogger(__name__)

# ============================================
# CLASE AI SERVICE (Simplificada)
# ============================================

class AIService:
    """
    Servicio de IA usando solo LLM para todo el procesamiento

    Arquitectura:
    - Sentiment Analysis: LLM via Groq
    - Category Classification: LLM via Groq

    Ventajas:
    - Consistencia entre desarrollo y producciÃ³n
    - Menor uso de memoria (~150MB)
    - Simple y mantenible
    """

    def __init__(self):
        """Inicializar servicio de IA"""
        logger.info("ðŸ¤– Inicializando servicio de IA (solo LLM)...")
        self._init_llm_model()
        logger.info("âœ… Servicio de IA inicializado correctamente")

    # ============================================
    # INICIALIZACIÃ“N
    # ============================================

    def _init_llm_model(self):
        """Inicializar LLM (Groq) para todo el procesamiento"""
        try:
            logger.info(f"ðŸ§  Inicializando LLM: {settings.groq_model}")

            self.llm = ChatGroq(
                model=settings.groq_model,
                temperature=0,  # DeterminÃ­stico
                groq_api_key=settings.groq_api_key,
                max_tokens=500
            )

            logger.info("âœ… LLM inicializado correctamente")

        except Exception as e:
            logger.error(f"âŒ Error inicializando LLM: {str(e)}")
            raise

    # ============================================
    # PROCESAMIENTO COMPLETO (Un solo prompt)
    # ============================================

    def process_ticket(self, description: str) -> Dict[str, Any]:
        """
        Procesar ticket completo con un solo llamado al LLM

        Args:
            description: DescripciÃ³n del ticket

        Returns:
            Dict con anÃ¡lisis completo (category + sentiment)
        """
        try:
            logger.info("ðŸš€ Procesando ticket con LLM...")
            total_start_time = time.time()

            # Crear prompt Ãºnico que analiza todo
            combined_prompt = ChatPromptTemplate.from_messages([
                ("system", """Eres un experto en anÃ¡lisis y clasificaciÃ³n de tickets de soporte.

**Tu tarea:**
1. Analizar el ticket
2. Clasificar en una categorÃ­a
3. Determinar el sentimiento
4. Explicar tus decisiones
5. Asignar nivel de confianza
6. Extraer palabras clave

**CATEGORÃAS:**
- TÃ©cnico: Problemas de servicio, conectividad, errores tÃ©cnicos, fallas
- FacturaciÃ³n: Cobros, pagos, facturas, precios, renovaciones, suscripciones
- Comercial: Consultas sobre productos, ventas, informaciÃ³n general, nuevos servicios

**SENTIMIENTOS:**
- Positivo: Cliente satisfecho, agradecido, contento
- Neutral: Cliente informativo, sin emociÃ³n clara
- Negativo: Cliente frustrado, enojado, insatisfecho, urgente

Responde ÃšNICAMENTE en formato JSON vÃ¡lido."""),
                ("user", """Analiza este ticket:

"{description}"

Responde en formato JSON vÃ¡lido:
{{
  "category": "TÃ©cnico" o "FacturaciÃ³n" o "Comercial",
  "category_reasoning": "explicaciÃ³n breve por quÃ© esta categorÃ­a",
  "sentiment": "Positivo" o "Neutral" o "Negativo",
  "sentiment_reasoning": "explicaciÃ³n breve del sentimiento",
  "confidence": 0.85,
  "keywords": ["palabra1", "palabra2", "palabra3"]
}}""")
            ])

            # Ejecutar LLM
            chain = combined_prompt | self.llm
            response = chain.invoke({"description": description})

            # Parsear respuesta JSON
            content = response.content
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                result = json.loads(json_str)
            else:
                result = json.loads(content)

            # Validar y normalizar categorÃ­a
            category = result.get("category", "Comercial")
            if category not in ["TÃ©cnico", "FacturaciÃ³n", "Comercial"]:
                logger.warning(f"âš ï¸ CategorÃ­a invÃ¡lida: {category}, usando Comercial")
                category = "Comercial"

            # Validar y normalizar sentimiento
            sentiment = result.get("sentiment", "Neutral")
            if sentiment not in ["Positivo", "Neutral", "Negativo"]:
                logger.warning(f"âš ï¸ Sentimiento invÃ¡lido: {sentiment}, usando Neutral")
                sentiment = "Neutral"

            # Calcular tiempo
            total_elapsed_time = int((time.time() - total_start_time) * 1000)

            # Construir respuesta
            combined_result = {
                "category": category,
                "category_reasoning": result.get("category_reasoning", "ClasificaciÃ³n automÃ¡tica"),
                "sentiment": sentiment,
                "sentiment_reasoning": result.get("sentiment_reasoning", "AnÃ¡lisis automÃ¡tico"),
                "confidence": float(result.get("confidence", 0.8)),
                "keywords": result.get("keywords", []),
                "processing_time_ms": total_elapsed_time,
                "models_used": [settings.groq_model]
            }

            logger.info(f"âœ… Procesamiento completado en {total_elapsed_time}ms")
            logger.info(f"   CategorÃ­a: {combined_result['category']}")
            logger.info(f"   Sentimiento: {combined_result['sentiment']}")
            logger.info(f"   Confianza: {combined_result['confidence']:.2f}")

            return combined_result

        except Exception as e:
            logger.error(f"âŒ Error en procesamiento: {str(e)}")
            # Fallback con clasificaciÃ³n por keywords
            return self._fallback_processing(description)

    def _fallback_processing(self, text: str) -> Dict[str, Any]:
        """
        Procesamiento de respaldo si el LLM falla
        ClasificaciÃ³n simple por keywords
        """
        logger.warning("âš ï¸ Usando clasificaciÃ³n de respaldo por keywords")

        text_lower = text.lower()

        # Keywords por categorÃ­a
        tech_keywords = ["internet", "conexiÃ³n", "no funciona", "error", "caÃ­do", "lento", "wifi", "servidor"]
        billing_keywords = ["factura", "cobro", "pago", "precio", "tarifa", "suscripciÃ³n"]
        commercial_keywords = ["informaciÃ³n", "plan", "producto", "servicio", "contratar", "consulta"]

        # Keywords por sentimiento
        positive_keywords = ["excelente", "gracias", "perfecto", "bien", "bueno", "contento"]
        negative_keywords = ["problema", "error", "no funciona", "mal", "urgente", "frustrado"]

        # Contar matches
        tech_score = sum(1 for k in tech_keywords if k in text_lower)
        billing_score = sum(1 for k in billing_keywords if k in text_lower)
        commercial_score = sum(1 for k in commercial_keywords if k in text_lower)

        # Determinar categorÃ­a
        scores = {"TÃ©cnico": tech_score, "FacturaciÃ³n": billing_score, "Comercial": commercial_score}
        category = max(scores, key=scores.get) if max(scores.values()) > 0 else "Comercial"

        # Determinar sentimiento
        positive_count = sum(1 for k in positive_keywords if k in text_lower)
        negative_count = sum(1 for k in negative_keywords if k in text_lower)

        if negative_count > positive_count:
            sentiment = "Negativo"
        elif positive_count > negative_count:
            sentiment = "Positivo"
        else:
            sentiment = "Neutral"

        return {
            "category": category,
            "category_reasoning": "ClasificaciÃ³n por keywords (mÃ©todo de respaldo)",
            "sentiment": sentiment,
            "sentiment_reasoning": "AnÃ¡lisis por keywords (mÃ©todo de respaldo)",
            "confidence": 0.6,
            "keywords": [],
            "processing_time_ms": 0,
            "models_used": ["fallback-keywords"]
        }

    # ============================================
    # HEALTH CHECK
    # ============================================

    def health_check(self) -> Dict[str, str]:
        """
        Verificar estado del servicio de IA

        Returns:
            Dict con estado de cada componente
        """
        status = {}

        # Verificar LLM
        try:
            # Test simple
            status["llm_model"] = "healthy"
        except Exception as e:
            status["llm_model"] = f"error: {str(e)}"

        return status


# ============================================
# INSTANCIA GLOBAL (Singleton)
# ============================================

_ai_service_instance: Optional[AIService] = None

def get_ai_service() -> AIService:
    """
    Obtener instancia singleton del servicio de IA

    Returns:
        AIService instance
    """
    global _ai_service_instance

    if _ai_service_instance is None:
        _ai_service_instance = AIService()

    return _ai_service_instance
