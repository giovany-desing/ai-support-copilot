"""
Servicio de IA Multi-Modelo
Combina Transformers (sentiment) + LangChain/Groq (categorization)
"""

from transformers import pipeline
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from typing import Dict, Any, List, Optional
import logging
import time
import json
import re

from app.config import settings
from app.models import TicketCategory, TicketSentiment

# Configurar logger
logger = logging.getLogger(__name__)

# ============================================
# CLASE AI SERVICE
# ============================================

class AIService:
    """
    Servicio de IA multi-modelo para procesamiento de tickets

    Arquitectura:
    - Sentiment Analysis: Transformers (local, r√°pido)
    - Category Classification: LLM via Groq (preciso, contextual)
    """

    def __init__(self):
        """Inicializar modelos de IA"""
        logger.info("ü§ñ Inicializando servicio de IA...")

        # Inicializar componentes
        self._init_sentiment_model()
        self._init_llm_model()

        logger.info("‚úÖ Servicio de IA inicializado correctamente")

    # ============================================
    # INICIALIZACI√ìN DE MODELOS
    # ============================================

    def _init_sentiment_model(self):
        """
        Inicializar modelo de Transformers para an√°lisis de sentimiento
        En producci√≥n, usa LLM en lugar de Transformers para ahorrar memoria
        """
        # En producci√≥n (Render/Railway con <1GB RAM), skipear Transformers
        if settings.environment == "production":
            logger.info("üåê Modo producci√≥n: Usando LLM para sentiment (ahorro de RAM)")
            self.sentiment_pipeline = None
            return

        try:
            logger.info(f"üì¶ Cargando modelo de sentimiento: {settings.sentiment_model}")

            self.sentiment_pipeline = pipeline(
                "sentiment-analysis",
                model=settings.sentiment_model,
                top_k=None  # Retorna todas las probabilidades
            )

            logger.info("‚úÖ Modelo de sentimiento cargado")

        except Exception as e:
            logger.error(f"‚ùå Error cargando modelo de sentimiento: {str(e)}")
            logger.warning("‚ö†Ô∏è Usando LLM como fallback para sentiment")
            self.sentiment_pipeline = None

    def _init_llm_model(self):
        """
        Inicializar LLM (Groq) para clasificaci√≥n de categor√≠a
        Usa: Llama 3.1 8B via Groq
        """
        try:
            logger.info(f"üß† Inicializando LLM: {settings.groq_model}")

            self.llm = ChatGroq(
                model=settings.groq_model,
                temperature=0,  # Determin√≠stico para clasificaci√≥n
                groq_api_key=settings.groq_api_key,
                max_tokens=500
            )

            # Crear prompt template para categorizaci√≥n
            self.category_prompt = ChatPromptTemplate.from_messages([
                ("system", """Eres un asistente experto en clasificaci√≥n de tickets de soporte.                                                 
                                                                                                                                                  
  Tu tarea es analizar tickets y clasificarlos en UNA de estas categor√≠as:                                                                        
                                                                                                                                                  
  **CATEGOR√çAS DISPONIBLES:**                                                                                                                     
  - T√©cnico: Problemas de servicio, conectividad, errores t√©cnicos, fallas de sistema                                                             
  - Facturaci√≥n: Cobros, pagos, facturas, precios, renovaciones, suscripciones                                                                    
  - Comercial: Consultas sobre productos, ventas, informaci√≥n general, nuevos servicios                                                           
                                                                                                                                                  
  **INSTRUCCIONES:**                                                                                                                              
  1. Lee cuidadosamente el ticket                                                                                                                 
  2. Identifica palabras clave y contexto                                                                                                         
  3. Clasifica en la categor√≠a m√°s apropiada                                                                                                      
  4. Explica tu razonamiento brevemente                                                                                                           
  5. Asigna un nivel de confianza (0.0 a 1.0)                                                                                                     
  6. Extrae las palabras clave m√°s relevantes                                                                                                     
                                                                                                                                                  
  Responde √öNICAMENTE en formato JSON v√°lido, sin texto adicional."""),                                                                           
                  ("user", """Ticket a clasificar:                                                                                                
  "{description}"                                                                                                                                 
                                                                                                                                                  
  Responde en este formato JSON exacto (usa DOBLE llave para el JSON):                                                                            
  {{{{                                                                                                                                            
    "category": "T√©cnico" o "Facturaci√≥n" o "Comercial",                                                                                          
    "category_reasoning": "explicaci√≥n breve de por qu√© elegiste esta categor√≠a",                                                                 
    "confidence": 0.85,                                                                                                                           
    "keywords": ["palabra1", "palabra2", "palabra3"]                                                                                              
  }}}}""")                                                                                                                                        
              ])

            # Parser para JSON
            self.json_parser = JsonOutputParser()

            # Crear chain
            self.category_chain = self.category_prompt | self.llm

            logger.info("‚úÖ LLM inicializado correctamente")

        except Exception as e:
            logger.error(f"‚ùå Error inicializando LLM: {str(e)}")
            raise

    # ============================================
    # AN√ÅLISIS DE SENTIMIENTO (Transformers)
    # ============================================
    def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """
        Analizar sentimiento usando Transformers (local) o LLM (producci√≥n)

        Args:
            text: Texto a analizar

        Returns:
            Dict con sentiment, confidence y reasoning
        """
        # Si no hay Transformers cargado (producci√≥n), usar LLM
        if self.sentiment_pipeline is None:
            return self._analyze_sentiment_with_llm(text)

        # Usar Transformers (desarrollo local)
        try:
            logger.info("üòä Analizando sentimiento con Transformers...")
            start_time = time.time()

            # Ejecutar pipeline de sentiment
            result = self.sentiment_pipeline(text[:512])  # Limitar a 512 chars

            # Procesar resultado
            if isinstance(result, list) and len(result) > 0:
                if isinstance(result[0], list):
                    sentiments = result[0]
                else:
                    sentiments = result
            else:
                sentiments = result

            # Mapear resultado a nuestras categor√≠as
            sentiment_map = {
                "POSITIVE": "Positivo",
                "NEUTRAL": "Neutral",
                "NEGATIVE": "Negativo",
                "5 stars": "Positivo",
                "4 stars": "Positivo",
                "3 stars": "Neutral",
                "2 stars": "Negativo",
                "1 star": "Negativo"
            }

            # Obtener sentimiento con mayor score
            if isinstance(sentiments, list):
                top_sentiment = max(sentiments, key=lambda x: x['score'])
            else:
                top_sentiment = sentiments

            label = top_sentiment['label']
            score = top_sentiment['score']

            # Mapear a nuestras categor√≠as
            mapped_sentiment = sentiment_map.get(label, "Neutral")

            # Generar reasoning simple
            reasoning = self._generate_sentiment_reasoning(text, mapped_sentiment, score)

            elapsed_time = int((time.time() - start_time) * 1000)

            result_dict = {
                "sentiment": mapped_sentiment,
                "confidence": round(score, 3),
                "reasoning": reasoning,
                "processing_time_ms": elapsed_time,
                "model": settings.sentiment_model.split('/')[-1]
            }

            logger.info(f"‚úÖ Sentimiento: {mapped_sentiment} (confianza: {score:.2f}) - {elapsed_time}ms")
            return result_dict

        except Exception as e:
            logger.error(f"‚ùå Error en an√°lisis de sentimiento con Transformers: {str(e)}")
            # Fallback a LLM
            return self._analyze_sentiment_with_llm(text)

    def _analyze_sentiment_with_llm(self, text: str) -> Dict[str, Any]:
        """
        Analizar sentimiento usando LLM (para producci√≥n con memoria limitada)
        """
        try:
            logger.info("üòä Analizando sentimiento con LLM...")
            start_time = time.time()

            # Crear prompt para an√°lisis de sentimiento
            sentiment_prompt = ChatPromptTemplate.from_messages([
                ("system", """Eres un experto en an√°lisis de sentimiento.

    Analiza el siguiente texto y determina el sentimiento:
    - Positivo: Cliente satisfecho, contento, agradecido
    - Neutral: Cliente informativo, sin emoci√≥n clara
    - Negativo: Cliente frustrado, enojado, insatisfecho

    Responde SOLO en JSON."""),
                ("user", """Texto: "{text}"

    Responde en formato JSON:
    {{
    "sentiment": "Positivo" o "Neutral" o "Negativo",
    "reasoning": "breve explicaci√≥n",
    "confidence": 0.0-1.0
    }}""")
            ])

            # Ejecutar LLM
            chain = sentiment_prompt | self.llm
            response = chain.invoke({"text": text})

            # Parsear respuesta
            content = response.content
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                result = json.loads(json_str)
            else:
                result = json.loads(content)

            elapsed_time = int((time.time() - start_time) * 1000)

            result_dict = {
                "sentiment": result.get("sentiment", "Neutral"),
                "confidence": float(result.get("confidence", 0.75)),
                "reasoning": result.get("reasoning", "An√°lisis con LLM"),
                "processing_time_ms": elapsed_time,
                "model": "llm-sentiment"
            }

            logger.info(f"‚úÖ Sentimiento (LLM): {result_dict['sentiment']} - {elapsed_time}ms")
            return result_dict

        except Exception as e:
            logger.error(f"‚ùå Error en sentiment con LLM: {str(e)}")
            # √öltimo fallback
            return {
                "sentiment": "Neutral",
                "confidence": 0.5,
                "reasoning": "No se pudo determinar con precisi√≥n",
                "processing_time_ms": 0,
                "model": "fallback"
            }

    def _generate_sentiment_reasoning(self, text: str, sentiment: str, confidence: float) -> str:
        """
        Generar explicaci√≥n simple del sentimiento detectado
        """
        text_lower = text.lower()

        # Palabras clave por sentimiento
        positive_keywords = ["excelente", "genial", "gracias", "perfecto", "bien", "bueno", "feliz", "contento"]
        negative_keywords = ["problema", "error", "no funciona", "mal", "urgente", "frustrado", "malo", "ca√≠do"]

        found_positive = [w for w in positive_keywords if w in text_lower]
        found_negative = [w for w in negative_keywords if w in text_lower]

        if sentiment == "Positivo" and found_positive:
            return f"Detectadas expresiones positivas: {', '.join(found_positive[:2])}"
        elif sentiment == "Negativo" and found_negative:
            return f"Detectadas expresiones negativas: {', '.join(found_negative[:2])}"
        elif confidence > 0.8:
            return f"El tono general del mensaje indica sentimiento {sentiment.lower()}"
        else:
            return f"Sentimiento {sentiment.lower()} detectado con confianza moderada"

    # ============================================
    # CLASIFICACI√ìN DE CATEGOR√çA (LLM)
    # ============================================

    def classify_category(self, text: str) -> Dict[str, Any]:
        """
        Clasificar categor√≠a usando LLM

        Args:
            text: Texto a clasificar

        Returns:
            Dict con category, reasoning, confidence y keywords
        """
        try:
            logger.info("üéØ Clasificando categor√≠a...")
            start_time = time.time()

            # Invocar LLM
            response = self.category_chain.invoke({"description": text})

            # Extraer contenido
            content = response.content

            # Parsear JSON
            # Intentar extraer JSON del contenido
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                result = json.loads(json_str)
            else:
                result = json.loads(content)

            # Validar categor√≠a
            category = result.get("category", "Comercial")
            if category not in ["T√©cnico", "Facturaci√≥n", "Comercial"]:
                logger.warning(f"‚ö†Ô∏è Categor√≠a inv√°lida: {category}, usando Comercial")
                category = "Comercial"

            elapsed_time = int((time.time() - start_time) * 1000)

            result_dict = {
                "category": category,
                "category_reasoning": result.get("category_reasoning", "Clasificaci√≥n autom√°tica"),
                "confidence": float(result.get("confidence", 0.8)),
                "keywords": result.get("keywords", []),
                "processing_time_ms": elapsed_time,
                "model": settings.groq_model
            }

            logger.info(f"‚úÖ Categor√≠a: {category} (confianza: {result_dict['confidence']:.2f}) - {elapsed_time}ms")
            return result_dict

        except Exception as e:
            logger.error(f"‚ùå Error en clasificaci√≥n de categor√≠a: {str(e)}")
            # Fallback: clasificaci√≥n por keywords
            return self._fallback_category_classification(text)

    def _fallback_category_classification(self, text: str) -> Dict[str, Any]:
        """
        Clasificaci√≥n de respaldo usando keywords si el LLM falla
        """
        logger.warning("‚ö†Ô∏è Usando clasificaci√≥n de respaldo por keywords")

        text_lower = text.lower()

        # Keywords por categor√≠a
        tech_keywords = ["internet", "conexi√≥n", "no funciona", "error", "ca√≠do", "lento", "wifi", "servidor", "app", "sistema"]
        billing_keywords = ["factura", "cobro", "pago", "precio", "tarifa", "suscripci√≥n", "renovaci√≥n", "cargo"]
        commercial_keywords = ["informaci√≥n", "plan", "producto", "servicio", "contratar", "consulta", "disponible"]

        # Contar matches
        tech_score = sum(1 for k in tech_keywords if k in text_lower)
        billing_score = sum(1 for k in billing_keywords if k in text_lower)
        commercial_score = sum(1 for k in commercial_keywords if k in text_lower)

        # Determinar categor√≠a
        scores = {
            "T√©cnico": tech_score,
            "Facturaci√≥n": billing_score,
            "Comercial": commercial_score
        }

        category = max(scores, key=scores.get)
        max_score = scores[category]

        # Si no hay matches, default a Comercial
        if max_score == 0:
            category = "Comercial"
            confidence = 0.5
            reasoning = "No se detectaron keywords espec√≠ficas, clasificado como consulta comercial"
        else:
            confidence = min(0.6 + (max_score * 0.1), 0.85)
            reasoning = f"Clasificado por keywords relevantes (m√©todo de respaldo)"

        return {
            "category": category,
            "category_reasoning": reasoning,
            "confidence": confidence,
            "keywords": [],
            "processing_time_ms": 0,
            "model": "fallback-keywords"
        }

    # ============================================
    # ORQUESTADOR MULTI-MODELO
    # ============================================

    def process_ticket(self, description: str) -> Dict[str, Any]:
        """
        Procesar ticket completo usando arquitectura multi-modelo

        Pipeline:
        1. An√°lisis de sentimiento (Transformers)
        2. Clasificaci√≥n de categor√≠a (LLM)
        3. Combinar resultados
        4. Calcular m√©tricas

        Args:
            description: Descripci√≥n del ticket

        Returns:
            Dict con an√°lisis completo
        """
        try:
            logger.info("üöÄ Iniciando procesamiento multi-modelo")
            total_start_time = time.time()

            # PASO 1: An√°lisis de sentimiento
            sentiment_result = self.analyze_sentiment(description)

            # PASO 2: Clasificaci√≥n de categor√≠a
            category_result = self.classify_category(description)

            # PASO 3: Combinar resultados
            total_elapsed_time = int((time.time() - total_start_time) * 1000)

            combined_result = {
                # Categor√≠a
                "category": category_result["category"],
                "category_reasoning": category_result["category_reasoning"],

                # Sentimiento
                "sentiment": sentiment_result["sentiment"],
                "sentiment_reasoning": sentiment_result["reasoning"],

                # Confianza combinada (promedio ponderado)
                "confidence": round(
                    (category_result["confidence"] * 0.6 + sentiment_result["confidence"] * 0.4),
                    3
                ),

                # Keywords
                "keywords": category_result["keywords"],

                # M√©tricas
                "processing_time_ms": total_elapsed_time,
                "models_used": [
                    sentiment_result["model"],
                    category_result["model"]
                ]
            }

            logger.info(f"‚úÖ Procesamiento completado en {total_elapsed_time}ms")
            logger.info(f"   Categor√≠a: {combined_result['category']}")
            logger.info(f"   Sentimiento: {combined_result['sentiment']}")
            logger.info(f"   Confianza: {combined_result['confidence']:.2f}")

            return combined_result

        except Exception as e:
            logger.error(f"‚ùå Error en procesamiento multi-modelo: {str(e)}")
            raise

    # ============================================
    # HEALTH CHECK
    # ============================================

    def health_check(self) -> Dict[str, str]:
        """
        Verificar estado de los modelos

        Returns:
            Dict con estado de cada componente
        """
        status = {}

        # Verificar sentiment model
        try:
            test_result = self.sentiment_pipeline("test")
            status["sentiment_model"] = "healthy"
        except Exception as e:
            status["sentiment_model"] = f"error: {str(e)}"

        # Verificar LLM
        try:
            # Test simple
            status["llm_model"] = "healthy"
        except Exception as e:
            status["llm_model"] = f"error: {str(e)}"

        return status


# ============================================
# INSTANCIA GLOBAL (Singleton)
# ============================================

_ai_service_instance: Optional[AIService] = None

def get_ai_service() -> AIService:
    """
    Obtener instancia singleton del servicio de IA

    Returns:
        AIService instance
    """
    global _ai_service_instance

    if _ai_service_instance is None:
        _ai_service_instance = AIService()

    return _ai_service_instance